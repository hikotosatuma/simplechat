#lambda/index.py
import json
import boto3
import logging
import os
import base64
import io
import re

# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Bedrockã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')

def remove_markdown_formatting(text):
    """ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’å‰Šé™¤ã™ã‚‹é–¢æ•°"""
    import re
    
    # **å¼·èª¿** ã‚’å‰Šé™¤
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
    
    # *æ–œä½“* ã‚’å‰Šé™¤
    text = re.sub(r'\*(.*?)\*', r'\1', text)
    
    # ***å¤ªå­—æ–œä½“*** ã‚’å‰Šé™¤
    text = re.sub(r'\*\*\*(.*?)\*\*\*', r'\1', text)
    
    # `ã‚³ãƒ¼ãƒ‰` ã‚’å‰Šé™¤
    text = re.sub(r'`(.*?)`', r'\1', text)
    
    # [ãƒªãƒ³ã‚¯](url) ã‚’å‰Šé™¤
    text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
    
    return text

def extract_text_from_pdf(file_content):
    """PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆPyPDF2ä½¿ç”¨ï¼‰"""
    try:
        import PyPDF2
        pdf_file = io.BytesIO(file_content)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        logger.error(f"PDF processing error: {str(e)}")
        return f"PDFã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def extract_text_from_ppt_legacy(file_content):
    """å¤ã„å½¢å¼ã®PPTãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    try:
        import re
        import struct
        
        logger.info("Processing legacy PPT file")
        
        # PPTãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        # è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§è©¦è¡Œã—ã€æœ€ã‚‚èª­ã¿ã‚„ã™ã„çµæœã‚’è¿”ã™
        
        extracted_texts = []
        
        # æ–¹æ³•1: UTF-8ã§è©¦è¡Œ
        try:
            text_utf8 = file_content.decode('utf-8', errors='ignore')
            # è‹±æ•°å­—ã¨æ—¥æœ¬èªæ–‡å­—ã‚’æŠ½å‡º
            readable_chars = re.findall(r'[a-zA-Z0-9\s\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF.,!?;:\-()\'\"]{4,}', text_utf8)
            utf8_texts = [s.strip() for s in readable_chars if len(s.strip()) >= 4]
            extracted_texts.extend(utf8_texts[:20])  # æœ€å¤§20å€‹
        except:
            pass
        
        # æ–¹æ³•2: Shift-JISï¼ˆæ—¥æœ¬èªï¼‰ã§è©¦è¡Œ
        try:
            text_sjis = file_content.decode('shift-jis', errors='ignore')
            readable_chars = re.findall(r'[a-zA-Z0-9\s\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF.,!?;:\-()\'\"]{4,}', text_sjis)
            sjis_texts = [s.strip() for s in readable_chars if len(s.strip()) >= 4]
            extracted_texts.extend(sjis_texts[:20])
        except:
            pass
        
        # æ–¹æ³•3: ãƒã‚¤ãƒˆåˆ—ã‹ã‚‰ç›´æ¥è‹±æ•°å­—ã‚’æ¤œç´¢
        try:
            ascii_strings = re.findall(rb'[a-zA-Z0-9\s.,!?;:\-()\'\"]{4,}', file_content)
            ascii_texts = [s.decode('ascii', errors='ignore').strip() for s in ascii_strings]
            ascii_texts = [s for s in ascii_texts if len(s) >= 4 and s.isascii()]
            extracted_texts.extend(ascii_texts[:15])
        except:
            pass
        
        # é‡è¤‡é™¤å»ã¨å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        unique_texts = []
        seen = set()
        
        for text in extracted_texts:
            clean_text = re.sub(r'\s+', ' ', text.strip())  # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’ä¸€ã¤ã«
            
            if (clean_text and 
                len(clean_text) >= 4 and 
                len(clean_text) <= 100 and 
                clean_text not in seen and
                not re.match(r'^[^\w\s]*$', clean_text) and  # è¨˜å·ã®ã¿ã§ãªã„
                not re.match(r'^[\x00-\x1F\x7F-\x9F]+$', clean_text)):  # åˆ¶å¾¡æ–‡å­—ã®ã¿ã§ãªã„
                
                unique_texts.append(clean_text)
                seen.add(clean_text)
        
        # çµæœã‚’ç”Ÿæˆ
        if unique_texts:
            # æ–‡å­—æ•°ã§æ˜‡é †ã‚½ãƒ¼ãƒˆï¼ˆçŸ­ã„ã‚‚ã®ã‹ã‚‰ï¼‰
            unique_texts.sort(key=len)
            
            result = "--- PPTãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼å½¢å¼ï¼‰ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ ---\n\n"
            
            # æœ€å¤§15å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
            displayed_texts = unique_texts[:15]
            for i, text in enumerate(displayed_texts, 1):
                result += f"{i}. {text}\n"
            
            if len(unique_texts) > 15:
                result += f"\n... ä»–ã«{len(unique_texts) - 15}å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆæ–­ç‰‡ãŒã‚ã‚Šã¾ã™\n"
            
            result += "\næ³¨æ„: å¤ã„PPTå½¢å¼ã®ãŸã‚ã€æ–‡å­—åŒ–ã‘ã‚„ä¸å®Œå…¨ãªæŠ½å‡ºãŒç™ºç”Ÿã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"
            result += "\nã‚ˆã‚Šæ­£ç¢ºãªæŠ½å‡ºã®ãŸã‚ã€PowerPointã§.pptxå½¢å¼ã«å¤‰æ›ã—ã¦ã‹ã‚‰å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
            
            return result
        else:
            return ("PPTãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
                   "ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¤ã„PowerPointå½¢å¼ã®ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãŒå›°é›£ã§ã™ã€‚\n"
                   "è§£æ±ºç­–: PowerPointã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã€ã€Œåå‰ã‚’ä»˜ã‘ã¦ä¿å­˜ã€ã§ .pptx å½¢å¼ã«å¤‰æ›ã—ã¦ã‹ã‚‰å†åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            
    except Exception as e:
        logger.error(f"PPT legacy processing error: {str(e)}")
        return f"å¤ã„PPTãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n\nè§£æ±ºç­–: PowerPointã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã€.pptxå½¢å¼ã§ä¿å­˜ã—ç›´ã—ã¦ãã ã•ã„ã€‚"

def extract_text_from_pptx(file_content):
    """PPTXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆpython-pptxä½¿ç”¨ï¼‰"""
    try:
        from pptx import Presentation
        pptx_file = io.BytesIO(file_content)
        prs = Presentation(pptx_file)
        text = ""
        for slide_num, slide in enumerate(prs.slides, 1):
            text += f"--- ã‚¹ãƒ©ã‚¤ãƒ‰ {slide_num} ---\n"
            for shape in slide.shapes:
                if hasattr(shape, "text") and shape.text.strip():
                    text += shape.text + "\n"
            text += "\n"
        return text.strip()
    except Exception as e:
        logger.error(f"PPTX processing error: {str(e)}")
        return f"PPTXã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def extract_text_from_docx(file_content):
    """DOCXã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆpython-docxä½¿ç”¨ï¼‰"""
    try:
        from docx import Document
        docx_file = io.BytesIO(file_content)
        doc = Document(docx_file)
        text = ""
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text += paragraph.text + "\n"
        return text.strip()
    except Exception as e:
        logger.error(f"DOCX processing error: {str(e)}")
        return f"DOCXã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def process_file_content(file_content, file_type, file_name):
    """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å‡¦ç†ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    logger.info(f"Processing file: {file_name}, type: {file_type}")
    
    try:
        if file_type == 'application/pdf' or file_name.lower().endswith('.pdf'):
            return extract_text_from_pdf(file_content)
        
        elif (file_type == 'application/vnd.openxmlformats-officedocument.presentationml.presentation' 
              or file_name.lower().endswith('.pptx')):
            return extract_text_from_pptx(file_content)
        
        elif (file_type == 'application/vnd.ms-powerpoint' 
              or file_name.lower().endswith('.ppt')):
            return extract_text_from_ppt_legacy(file_content)
        
        elif (file_type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
              or file_name.lower().endswith('.docx')):
            return extract_text_from_docx(file_content)
        
        elif (file_type == 'application/msword'
              or file_name.lower().endswith('.doc')):
            return "å¤ã„DOCãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚.docxå½¢å¼ã§ä¿å­˜ã—ç›´ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        
        elif file_type.startswith('text/') or file_name.lower().endswith('.txt'):
            return file_content.decode('utf-8')
        
        else:
            return f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {file_type}ã€‚å¯¾å¿œå½¢å¼: PDF, PPTX, PPT, DOCX, TXT"
    
    except Exception as e:
        logger.error(f"File processing error: {str(e)}")
        return f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"

def handle_file_upload(event):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’å‡¦ç†ï¼ˆLambdaå†…ã§å®Œçµï¼‰"""
    try:
        body = json.loads(event.get("body", "{}"))
        file_data = body.get("file")
        file_name = body.get("fileName")
        file_type = body.get("fileType", "")
        
        if not file_data or not file_name:
            return {
                "statusCode": 400,
                "headers": {
                    "Content-Type": "application/json",
                    "Access-Control-Allow-Origin": "*"
                },
                "body": json.dumps({
                    "success": False,
                    "error": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                })
            }
        
        # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
        try:
            file_content = base64.b64decode(file_data)
        except Exception as e:
            return {
                "statusCode": 400,
                "headers": {
                    "Content-Type": "application/json",
                    "Access-Control-Allow-Origin": "*"
                },
                "body": json.dumps({
                    "success": False,
                    "error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
                })
            }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ10MBåˆ¶é™ï¼‰
        if len(file_content) > 10 * 1024 * 1024:
            return {
                "statusCode": 400,
                "headers": {
                    "Content-Type": "application/json",
                    "Access-Control-Allow-Origin": "*"
                },
                "body": json.dumps({
                    "success": False,
                    "error": "ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ï¼ˆ10MBä»¥ä¸‹ã«ã—ã¦ãã ã•ã„ï¼‰"
                })
            }
        
        # Lambdaå†…ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        extracted_text = process_file_content(file_content, file_type, file_name)
        
        # æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
        if len(extracted_text) > 50000:  # 50KBåˆ¶é™
            extracted_text = extracted_text[:50000] + "\n...(ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹ãŸã‚åˆ‡ã‚Šè©°ã‚ã‚‰ã‚Œã¾ã—ãŸ)"
        
        return {
            "statusCode": 200,
            "headers": {
                "Content-Type": "application/json",
                "Access-Control-Allow-Origin": "*"
            },
            "body": json.dumps({
                "success": True,
                "message": "ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸ",
                "extracted_text": extracted_text,
                "file_name": file_name,
                "file_size": len(file_content),
                "text_length": len(extracted_text)
            })
        }
        
    except Exception as e:
        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        return {
            "statusCode": 500,
            "headers": {
                "Content-Type": "application/json",
                "Access-Control-Allow-Origin": "*"
            },
            "body": json.dumps({
                "success": False,
                "error": str(e)
            })
        }

def lambda_handler(event, context):
    try:
        logger.info(f"Received event: {json.dumps(event)}")
        
        # HTTPãƒ¡ã‚½ãƒƒãƒ‰ã¨ãƒ‘ã‚¹ã‚’å–å¾—
        http_method = event.get('httpMethod', '')
        path = event.get('path', '').rstrip('/')
        resource = event.get('resource', '')
        
        logger.info(f"HTTP Method: {http_method}, Path: {path}, Resource: {resource}")
        
        # OPTIONSãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆCORS preflightï¼‰ã¸ã®å¯¾å¿œ
        if http_method == 'OPTIONS':
            return {
                "statusCode": 200,
                "headers": {
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Headers": "Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token",
                    "Access-Control-Allow-Methods": "OPTIONS,POST"
                },
                "body": ""
            }
        
        # ãƒ‘ã‚¹ã«åŸºã¥ã„ã¦ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
        if '/upload' in path or '/upload' in resource:
            return handle_file_upload(event)
        elif '/chat' in path or '/chat' in resource:
            return handle_chat(event)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
            return handle_chat(event)
    
    except Exception as e:
        logger.error(f"Error in lambda_handler: {str(e)}", exc_info=True)
        return {
            "statusCode": 500,
            "headers": {
                "Content-Type": "application/json",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token",
                "Access-Control-Allow-Methods": "OPTIONS,POST"
            },
            "body": json.dumps({
                "success": False,
                "error": str(e)
            })
        }

def handle_chat(event):
    try:
        logger.info("Handling chat request")
        
        # 1) ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’å–å¾—ãƒ»è§£æ
        body = json.loads(event.get("body", "{}"))
        message = body.get("message", "")
        conversation_history = body.get("conversationHistory", [])
        uploaded_files = body.get("uploadedFiles", [])
        
        logger.info(f"Processing message: {message}")
        
        # 2) ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å«ã‚ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        context_message = message
        if uploaded_files:
            context_message = f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å‚è€ƒã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
            for file_info in uploaded_files:
                context_message += f"ãƒ•ã‚¡ã‚¤ãƒ«å: {file_info.get('name', 'Unknown')}\n"
                context_message += f"æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ: {file_info.get('extractedText', 'No text')}\n\n"
            context_message += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {message}"

        # 3) Nova Liteãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’ä½œæˆ
        messages = []
        
        # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é™¤ãï¼‰
        for msg in conversation_history:
            if msg.get("role") != "system":
                messages.append({
                    "role": msg["role"],
                    "content": [{"text": msg["content"]}]
                })
        
        # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        messages.append({
            "role": "user",
            "content": [{"text": context_message}]
        })

        payload = {
            "messages": messages,
            "inferenceConfig": {
                "temperature": 0.7,
                "topP": 0.9,
                "maxTokens": 1024
            }
        }
        
        logger.info(f"Bedrock payload: {json.dumps(payload, ensure_ascii=False)}")

        # 4) Bedrockã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’å®Ÿè¡Œ
        response = bedrock.invoke_model(
            modelId='us.amazon.nova-lite-v1:0',
            body=json.dumps(payload),
            contentType='application/json'
        )

        # 5) ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
        response_body = json.loads(response['body'].read())
        logger.info(f"Bedrock response: {json.dumps(response_body, ensure_ascii=False)}")
        
        # Nova Liteã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‹ã‚‰ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        generated_text = response_body['output']['message']['content'][0]['text']
        
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã‚’å‰Šé™¤ï¼ˆ**å¼·èª¿**ãªã©ï¼‰
        generated_text = remove_markdown_formatting(generated_text)

        # è¨˜è¿°å•é¡Œã®æ¡ç‚¹ãŒè¦æ±‚ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if is_essay_grading_request(message, context_message, uploaded_files):
            essay_score = grade_essay_answer(message, context_message, uploaded_files)
            if essay_score:
                generated_text = essay_score

        # 6) ä¼šè©±å±¥æ­´ã«æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        updated_history = conversation_history + [
            {"role": "user", "content": message},
            {"role": "assistant", "content": generated_text}
        ]

        # 7) æ­£å¸¸ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
        return {
            "statusCode": 200,
            "headers": {
                "Content-Type": "application/json",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token",
                "Access-Control-Allow-Methods": "OPTIONS,POST"
            },
            "body": json.dumps({
                "success": True,
                "response": generated_text,
                "conversationHistory": updated_history
            }, ensure_ascii=False)
        }

    except Exception as e:
        logger.error(f"Error occurred in chat: {str(e)}", exc_info=True)
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        return {
            "statusCode": 500,
            "headers": {
                "Content-Type": "application/json",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token",
                "Access-Control-Allow-Methods": "OPTIONS,POST"
            },
            "body": json.dumps({
                "success": False,
                "error": str(e)
            })
        }

def is_essay_grading_request(message, context_message, uploaded_files):
    """è¨˜è¿°å•é¡Œã®æ¡ç‚¹è¦æ±‚ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°"""
    # ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    grading_keywords = [
        'GRADE_ESSAY_ANSWER',  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰é€ä¿¡ã•ã‚Œã‚‹ç‰¹åˆ¥ãªãƒãƒ¼ã‚«ãƒ¼
        'è¨˜è¿°å•é¡Œã®å›ç­”ã‚’æ¡ç‚¹',
        'è¨˜è¿°å•é¡Œæ¡ç‚¹'
    ]
    
    for keyword in grading_keywords:
        if keyword in message or keyword in context_message:
            return True
    
    return False

def grade_essay_answer(message, context_message, uploaded_files):
    """è¨˜è¿°å•é¡Œã®å›ç­”ã‚’æ¡ç‚¹ã™ã‚‹é–¢æ•°"""
    try:
        logger.info("è¨˜è¿°å•é¡Œã®æ¡ç‚¹ã‚’é–‹å§‹")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ¡ç‚¹ã«å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡º
        import json
        
        # GRADE_ESSAY_ANSWERãƒãƒ¼ã‚«ãƒ¼ã®å¾Œã«JSONå½¢å¼ã§æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’æƒ³å®š
        if 'GRADE_ESSAY_ANSWER:' in message:
            json_part = message.split('GRADE_ESSAY_ANSWER:')[1].strip()
            try:
                grading_info = json.loads(json_part)
                user_answer = grading_info.get('userAnswer', '')
                question = grading_info.get('question', {})
                points = grading_info.get('points', [])
                explanation = grading_info.get('explanation', '')
                
                logger.info(f"æ¡ç‚¹æƒ…å ±: å•é¡Œ={question.get('question', '')[:50]}, å›ç­”é•·={len(user_answer)}, ãƒã‚¤ãƒ³ãƒˆæ•°={len(points)}")
                
                # Bedrockã‚’ä½¿ç”¨ã—ã¦æ¡ç‚¹
                grading_prompt = f"""ä»¥ä¸‹ã®è¨˜è¿°å•é¡Œã®å›ç­”ã‚’æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚

ã€å•é¡Œã€‘
{question.get('question', '')}

ã€å­¦ç”Ÿã®å›ç­”ã€‘
{user_answer}

ã€è§£ç­”ä¾‹ã€‘
{explanation}

ã€æ¡ç‚¹ãƒã‚¤ãƒ³ãƒˆã€‘
{chr(10).join([f"- {point}" for point in points])}

ã€æ¡ç‚¹æŒ‡ç¤ºã€‘
1. å„æ¡ç‚¹ãƒã‚¤ãƒ³ãƒˆã«ã¤ã„ã¦ã€å­¦ç”Ÿã®å›ç­”ãŒè©²å½“ã™ã‚‹ã‹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„
2. 100ç‚¹æº€ç‚¹ã§ç‚¹æ•°ã‚’ã¤ã‘ã¦ãã ã•ã„
3. å…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„
4. æ”¹å–„ç‚¹ãŒã‚ã‚Œã°æŒ‡æ‘˜ã—ã¦ãã ã•ã„

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

å¾—ç‚¹: XX/100ç‚¹

å„ãƒã‚¤ãƒ³ãƒˆã®è©•ä¾¡:
- ãƒã‚¤ãƒ³ãƒˆ1: â—‹/â–³/Ã—ï¼ˆç†ç”±ï¼‰
- ãƒã‚¤ãƒ³ãƒˆ2: â—‹/â–³/Ã—ï¼ˆç†ç”±ï¼‰
...

ç·åˆè©•ä¾¡:
ï¼ˆå…¨ä½“çš„ãªè©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆï¼‰

æ”¹å–„ç‚¹:
ï¼ˆå…·ä½“çš„ãªæ”¹å–„ææ¡ˆï¼‰"""

                # Bedrockã§æ¡ç‚¹ã‚’å®Ÿè¡Œ
                messages = [{
                    "role": "user",
                    "content": [{"text": grading_prompt}]
                }]

                payload = {
                    "messages": messages,
                    "inferenceConfig": {
                        "temperature": 0.3,  # æ¡ç‚¹ã§ã¯ä¸€è²«æ€§ã‚’é‡è¦–ã™ã‚‹ãŸã‚ä½ã‚ã«è¨­å®š
                        "topP": 0.8,
                        "maxTokens": 1024
                    }
                }

                response = bedrock.invoke_model(
                    modelId='us.amazon.nova-lite-v1:0',
                    body=json.dumps(payload),
                    contentType='application/json'
                )

                response_body = json.loads(response['body'].read())
                grading_result = response_body['output']['message']['content'][0]['text']
                
                # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’å‰Šé™¤
                grading_result = remove_markdown_formatting(grading_result)
                
                logger.info("è¨˜è¿°å•é¡Œã®æ¡ç‚¹ãŒå®Œäº†")
                return f"ğŸ“ è¨˜è¿°å•é¡Œã®æ¡ç‚¹çµæœ\n\n{grading_result}"
                
            except json.JSONDecodeError as e:
                logger.error(f"æ¡ç‚¹æƒ…å ±ã®JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
                return None
        
        return None
        
    except Exception as e:
        logger.error(f"è¨˜è¿°å•é¡Œæ¡ç‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
        return None
